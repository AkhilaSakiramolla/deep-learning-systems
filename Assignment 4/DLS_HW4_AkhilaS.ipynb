{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2vmHCDHGOHQp"
   },
   "source": [
    "# ENGR-E 533 Deep Learning Systems - Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3PkHhgI_OjGI"
   },
   "source": [
    "## Name : Akhila Sakiramolla (asakiram@iu.edu)\n",
    "## UID : 2000886005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StpT7Ru5On2B"
   },
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tPXx6g9pYmta"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import librosa\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import History \n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Dropout,LSTM, GRU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# To execute a cell line by line\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4MyXpVLkY3Z"
   },
   "source": [
    "## Problem 1: Network Compression Using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iIqq4ok3kbxC",
    "outputId": "693ef45b-27d0-4cd4-9a66-ae79571d094c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train.shape\n",
    "y_train.shape\n",
    "x_test.shape\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MCMLByCfBhZi"
   },
   "outputs": [],
   "source": [
    "# Reshaping the data\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Mk5nihcduyhS"
   },
   "outputs": [],
   "source": [
    "# Normalizing the data\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JMPeteM5Y90E"
   },
   "outputs": [],
   "source": [
    "# Converting labels to categorical\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "589CHbA3Ba-0",
    "outputId": "e8845cc7-37c8-4fd2-af4d-5d1c81c74b86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 1024)              803840    \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,012,490\n",
      "Trainable params: 5,012,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building a model and adding 5 hidden layers with 1024 hidden units and output layer with 10 units\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, input_dim = 784, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "model.add(Dense(1024, activation='relu', kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "model.add(Dense(10, activation='softmax', kernel_initializer=tf.keras.initializers.HeNormal()))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PIIpeoLg751e"
   },
   "source": [
    "For the base model, the total number of parameters = 5,012,490"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5m7EEuvK0n21"
   },
   "outputs": [],
   "source": [
    "# Calculating loss and optimizing it\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4dtJ8RK0yua",
    "outputId": "b0edfcc5-f86f-4b05-a293-e890c0f32782"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "118/118 [==============================] - 2s 10ms/step - loss: 0.2795 - accuracy: 0.9154 - val_loss: 0.0967 - val_accuracy: 0.9705\n",
      "Epoch 2/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0765 - accuracy: 0.9758 - val_loss: 0.1122 - val_accuracy: 0.9663\n",
      "Epoch 3/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0508 - accuracy: 0.9840 - val_loss: 0.0756 - val_accuracy: 0.9770\n",
      "Epoch 4/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0381 - accuracy: 0.9880 - val_loss: 0.0824 - val_accuracy: 0.9768\n",
      "Epoch 5/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 0.0936 - val_accuracy: 0.9752\n",
      "Epoch 6/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0212 - accuracy: 0.9934 - val_loss: 0.0926 - val_accuracy: 0.9766\n",
      "Epoch 7/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0192 - accuracy: 0.9937 - val_loss: 0.1008 - val_accuracy: 0.9759\n",
      "Epoch 8/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0233 - accuracy: 0.9923 - val_loss: 0.1055 - val_accuracy: 0.9748\n",
      "Epoch 9/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0198 - accuracy: 0.9937 - val_loss: 0.0927 - val_accuracy: 0.9781\n",
      "Epoch 10/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.1007 - val_accuracy: 0.9778\n",
      "Epoch 11/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0145 - accuracy: 0.9956 - val_loss: 0.0986 - val_accuracy: 0.9775\n",
      "Epoch 12/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0112 - accuracy: 0.9966 - val_loss: 0.0904 - val_accuracy: 0.9811\n",
      "Epoch 13/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 0.0845 - val_accuracy: 0.9808\n",
      "Epoch 14/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0127 - accuracy: 0.9965 - val_loss: 0.0929 - val_accuracy: 0.9779\n",
      "Epoch 15/70\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 0.0917 - val_accuracy: 0.9821\n",
      "Epoch 16/70\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 0.0158 - accuracy: 0.9954 - val_loss: 0.1199 - val_accuracy: 0.9780\n",
      "Epoch 17/70\n",
      "118/118 [==============================] - 1s 8ms/step - loss: 0.0095 - accuracy: 0.9970 - val_loss: 0.0952 - val_accuracy: 0.9816\n",
      "Epoch 18/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0114 - accuracy: 0.9967 - val_loss: 0.0839 - val_accuracy: 0.9810\n",
      "Epoch 19/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.1100 - val_accuracy: 0.9784\n",
      "Epoch 20/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0070 - accuracy: 0.9982 - val_loss: 0.0909 - val_accuracy: 0.9831\n",
      "Epoch 21/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9976 - val_loss: 0.0977 - val_accuracy: 0.9805\n",
      "Epoch 22/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0085 - accuracy: 0.9974 - val_loss: 0.1119 - val_accuracy: 0.9798\n",
      "Epoch 23/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0094 - accuracy: 0.9971 - val_loss: 0.0888 - val_accuracy: 0.9812\n",
      "Epoch 24/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0084 - accuracy: 0.9977 - val_loss: 0.0913 - val_accuracy: 0.9841\n",
      "Epoch 25/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0105 - accuracy: 0.9971 - val_loss: 0.0846 - val_accuracy: 0.9831\n",
      "Epoch 26/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0100 - accuracy: 0.9972 - val_loss: 0.1115 - val_accuracy: 0.9791\n",
      "Epoch 27/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.1033 - val_accuracy: 0.9813\n",
      "Epoch 28/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0093 - accuracy: 0.9975 - val_loss: 0.0901 - val_accuracy: 0.9809\n",
      "Epoch 29/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.0988 - val_accuracy: 0.9832\n",
      "Epoch 30/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 0.0992 - val_accuracy: 0.9839\n",
      "Epoch 31/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0993 - val_accuracy: 0.9826\n",
      "Epoch 32/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0068 - accuracy: 0.9985 - val_loss: 0.0944 - val_accuracy: 0.9826\n",
      "Epoch 33/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0097 - accuracy: 0.9973 - val_loss: 0.1147 - val_accuracy: 0.9793\n",
      "Epoch 34/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0104 - accuracy: 0.9972 - val_loss: 0.0861 - val_accuracy: 0.9823\n",
      "Epoch 35/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0036 - accuracy: 0.9991 - val_loss: 0.0932 - val_accuracy: 0.9841\n",
      "Epoch 36/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.0826 - val_accuracy: 0.9850\n",
      "Epoch 37/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0064 - accuracy: 0.9982 - val_loss: 0.0925 - val_accuracy: 0.9836\n",
      "Epoch 38/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0889 - val_accuracy: 0.9822\n",
      "Epoch 39/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0069 - accuracy: 0.9984 - val_loss: 0.1088 - val_accuracy: 0.9841\n",
      "Epoch 40/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0101 - accuracy: 0.9975 - val_loss: 0.0843 - val_accuracy: 0.9827\n",
      "Epoch 41/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0091 - accuracy: 0.9974 - val_loss: 0.0901 - val_accuracy: 0.9848\n",
      "Epoch 42/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.1177 - val_accuracy: 0.9819\n",
      "Epoch 43/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0057 - accuracy: 0.9984 - val_loss: 0.1319 - val_accuracy: 0.9815\n",
      "Epoch 44/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0083 - accuracy: 0.9982 - val_loss: 0.1143 - val_accuracy: 0.9830\n",
      "Epoch 45/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9986 - val_loss: 0.1067 - val_accuracy: 0.9822\n",
      "Epoch 46/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0050 - accuracy: 0.9988 - val_loss: 0.1030 - val_accuracy: 0.9844\n",
      "Epoch 47/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 0.9984 - val_loss: 0.0862 - val_accuracy: 0.9850\n",
      "Epoch 48/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0084 - accuracy: 0.9982 - val_loss: 0.1226 - val_accuracy: 0.9828\n",
      "Epoch 49/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0098 - accuracy: 0.9977 - val_loss: 0.1265 - val_accuracy: 0.9803\n",
      "Epoch 50/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.1248 - val_accuracy: 0.9816\n",
      "Epoch 51/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.1251 - val_accuracy: 0.9825\n",
      "Epoch 52/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.1153 - val_accuracy: 0.9847\n",
      "Epoch 53/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0073 - accuracy: 0.9984 - val_loss: 0.1099 - val_accuracy: 0.9807\n",
      "Epoch 54/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0065 - accuracy: 0.9985 - val_loss: 0.1166 - val_accuracy: 0.9821\n",
      "Epoch 55/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0061 - accuracy: 0.9987 - val_loss: 0.1162 - val_accuracy: 0.9834\n",
      "Epoch 56/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.1198 - val_accuracy: 0.9828\n",
      "Epoch 57/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.1147 - val_accuracy: 0.9843\n",
      "Epoch 58/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9993 - val_loss: 0.0998 - val_accuracy: 0.9856\n",
      "Epoch 59/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.1077 - val_accuracy: 0.9861\n",
      "Epoch 60/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 5.8494e-04 - accuracy: 0.9998 - val_loss: 0.1283 - val_accuracy: 0.9859\n",
      "Epoch 61/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.1533 - val_accuracy: 0.9821\n",
      "Epoch 62/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0081 - accuracy: 0.9983 - val_loss: 0.1214 - val_accuracy: 0.9797\n",
      "Epoch 63/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0969 - val_accuracy: 0.9827\n",
      "Epoch 64/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0057 - accuracy: 0.9986 - val_loss: 0.1174 - val_accuracy: 0.9831\n",
      "Epoch 65/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0034 - accuracy: 0.9993 - val_loss: 0.1217 - val_accuracy: 0.9808\n",
      "Epoch 66/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0046 - accuracy: 0.9988 - val_loss: 0.1099 - val_accuracy: 0.9846\n",
      "Epoch 67/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.1169 - val_accuracy: 0.9830\n",
      "Epoch 68/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0048 - accuracy: 0.9987 - val_loss: 0.1199 - val_accuracy: 0.9840\n",
      "Epoch 69/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.1104 - val_accuracy: 0.9855\n",
      "Epoch 70/70\n",
      "118/118 [==============================] - 1s 7ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.1157 - val_accuracy: 0.9854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e9a60c210>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "\n",
    "history = History()\n",
    "model.fit(x_train, y_train, epochs=70, batch_size=512, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y8ukrkOW1FEO",
    "outputId": "3765d42a-edc4-468d-bf96-aa2a3ef836f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1157 - accuracy: 0.9854\n",
      "Test accuracy: 98.54\n"
     ]
    }
   ],
   "source": [
    "# Calculating test accuarcy \n",
    "\n",
    "loss_base, accuracy_base = model.evaluate(x_test,  y_test)\n",
    "print(\"Test accuracy:\", round(accuracy_base*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "B8W2iNbabe2b"
   },
   "outputs": [],
   "source": [
    "# Saving model weights\n",
    "\n",
    "model.save_weights(\"model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kajo_NvFjuQC",
    "outputId": "7e924f6d-c44a-4b18-b8c1-0a7af20f725a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the weights and bias of the model\n",
    "\n",
    "model_wts = []\n",
    "model_bias = []\n",
    "for i in range(len(model.layers)):\n",
    "  model_wts.append(model.layers[i].get_weights()[0])\n",
    "  model_bias.append(model.layers[i].get_weights()[1])\n",
    "\n",
    "len(model_wts), len(model_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "tRg5UiaZm3vj"
   },
   "outputs": [],
   "source": [
    "# Performing svd on weights\n",
    "\n",
    "s = [[] for i in range(5)]\n",
    "u = [[] for i in range(5)]\n",
    "v = [[] for i in range(5)]\n",
    "\n",
    "for i in range(5):\n",
    "  s[i], u[i], v[i] = tf.linalg.svd(model_wts[i], compute_uv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcm4NMWfii5R",
    "outputId": "56d4e2c4-80d2-4505-dabf-2450ce084598"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TyhWGlBP7HPk"
   },
   "outputs": [],
   "source": [
    "# Function to set model weights based on D value\n",
    "\n",
    "def setWeights(D):\n",
    "  for i in range(5):\n",
    "      sv = tf.matmul(tf.linalg.diag(s[i][:D]), v[i][:,:D], adjoint_b=True)\n",
    "      wts = tf.matmul(u[i][:,:D], sv)\n",
    "      model.layers[i].set_weights((wts,model_bias[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "apakJIro3Ol8"
   },
   "outputs": [],
   "source": [
    "accuracy_vals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BjpfIhOI1YbN",
    "outputId": "6beb1003-cdda-4fa0-e461-3606e03c44c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.6351 - accuracy: 0.6418\n",
      "Test accuracy: 64.18\n"
     ]
    }
   ],
   "source": [
    "# Setting weights for D=10\n",
    "D=10\n",
    "setWeights(D)\n",
    "\n",
    "# Calculating test accuarcy \n",
    "loss1, accuracy1 = model.evaluate(x_test,  y_test)\n",
    "print(\"Test accuracy:\", round(accuracy1*100,2))\n",
    "accuracy_vals.append(accuracy1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzYkYhn59Efu"
   },
   "source": [
    "The total number of parameters when D = 10 is:\n",
    "10x1024 + 1024 + 10x1024 + 1024 + 10x1024 + 1024 + 10x1024 + 1024 + 10x1024 + 1024 + 10x1024 =  66,560\n",
    "\n",
    "This is 1.3% of base model parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FUFjhvnV1YKP",
    "outputId": "9729dc1e-8459-4c49-c787-287a94c29af7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3744 - accuracy: 0.9213\n",
      "Test accuracy: 92.13\n"
     ]
    }
   ],
   "source": [
    "# Setting weights for D=20\n",
    "D=20\n",
    "setWeights(D)\n",
    "\n",
    "# Calculating test accuarcy \n",
    "loss2, accuracy2 = model.evaluate(x_test,  y_test)\n",
    "print(\"Test accuracy:\", round(accuracy2*100,2))\n",
    "accuracy_vals.append(accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAtirlFA-0kk"
   },
   "source": [
    "The total number of parameters when D = 20 is:\n",
    "20x1024 + 1024 + 20x1024 + 1024 + 20x1024 + 1024 + 20x1024 + 1024 + 20x1024 + 1024 + 10x1024 = 117,760\n",
    "\n",
    "This is 2.3% of base model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXqhTYQI2_qo",
    "outputId": "4fdaaf0e-a7ee-4cb6-a45d-aa96e2f76191"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1085 - accuracy: 0.9813\n",
      "Test accuracy: 98.13\n"
     ]
    }
   ],
   "source": [
    "# Setting weights for D=50\n",
    "D=50\n",
    "setWeights(D)\n",
    "\n",
    "# Calculating test accuarcy \n",
    "loss3, accuracy3 = model.evaluate(x_test,  y_test)\n",
    "print(\"Test accuracy:\", round(accuracy3*100,2))\n",
    "accuracy_vals.append(accuracy3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HY2ZL1QC_Z7j"
   },
   "source": [
    "The total number of parameters when D = 20 is:\n",
    "50x1024 + 1024 + 50x1024 + 1024 + 50x1024 + 1024 + 50x1024 + 1024 + 50x1024 + 1024 + 10x1024 = 271,360\n",
    "\n",
    "This is 5.4% of base model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9xtKfvZz3Exa",
    "outputId": "a1c17ad3-b02e-4528-d86e-d622cda9b0a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1026 - accuracy: 0.9841\n",
      "Test accuracy: 98.41\n"
     ]
    }
   ],
   "source": [
    "# Setting weights for D=100\n",
    "D=100\n",
    "setWeights(D)\n",
    "\n",
    "# Calculating test accuarcy \n",
    "loss4, accuracy4 = model.evaluate(x_test,  y_test)\n",
    "print(\"Test accuracy:\", round(accuracy4*100,2))\n",
    "accuracy_vals.append(accuracy4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zg-RT3RD_jDc"
   },
   "source": [
    "The total number of parameters when D = 20 is:\n",
    "100x1024 + 1024 + 100x1024 + 1024 + 100x1024 + 1024 + 100x1024 + 1024 + 100x1024 + 1024 + 10x1024 = 527,360\n",
    "\n",
    "This is 10.5% of base model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-c_uAdOa3JOW",
    "outputId": "36e6e72f-77ee-4ed5-970d-3257632daa53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1031 - accuracy: 0.9855\n",
      "Test accuracy: 98.55\n"
     ]
    }
   ],
   "source": [
    "# Setting weights for D=200\n",
    "D=200\n",
    "setWeights(D)\n",
    "\n",
    "# Calculating test accuarcy \n",
    "loss5, accuracy5 = model.evaluate(x_test,  y_test)\n",
    "print(\"Test accuracy:\", round(accuracy5*100,2))\n",
    "accuracy_vals.append(accuracy5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPQGLLG8_xIK"
   },
   "source": [
    "The total number of parameters when D = 200 is:\n",
    "200x1024 + 1024 + 200x1024 + 1024 + 200x1024 + 1024 + 200x1024 + 1024 + 200x1024 + 1024 + 10x1024 = 1,039,360\n",
    "\n",
    "This is 20.7% of base model parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-v4HpvTj3XX7",
    "outputId": "f6ee4e67-283c-4aae-80b9-9a0c9c147b9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1157 - accuracy: 0.9854\n",
      "Test accuracy: 98.54\n"
     ]
    }
   ],
   "source": [
    "# Setting weights for D=Full\n",
    "D=1024\n",
    "\n",
    "for i in range(5):\n",
    "       #first layer\n",
    "      if i==0:\n",
    "        sv = tf.matmul(tf.linalg.diag(s[i][:784]), v[i][:,:784], adjoint_b=True)\n",
    "        wts = tf.matmul(u[i][:,:784], sv)\n",
    "        model.layers[i].set_weights((wts,model_bias[i]))\n",
    "      \n",
    "      else:\n",
    "        sv = tf.matmul(tf.linalg.diag(s[i][:D]), v[i][:,:D], adjoint_b=True)\n",
    "        wts = tf.matmul(u[i][:,:D], sv)\n",
    "        model.layers[i].set_weights((wts,model_bias[i]))\n",
    "\n",
    "\n",
    "# Calculating test accuarcy \n",
    "loss6, accuracy6 = model.evaluate(x_test,  y_test)\n",
    "print(\"Test accuracy:\", round(accuracy6*100,2))\n",
    "accuracy_vals.append(accuracy6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vUoZduKPADb-"
   },
   "source": [
    "The total number of parameters when D = 200 is: 784x1024 + 1024 + 1024x1024 + 1024 + 1024x1024 + 1024 + 1024x1024 + 1024 + 1024x1024 + 1024 + 10x1024 = 5,012,490\n",
    "\n",
    "This is same as the number of base model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4rnAGB6L3c0b",
    "outputId": "69d3dec1-e4b2-4f91-97b3-3e66de43a8c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6417999863624573,\n",
       " 0.9212999939918518,\n",
       " 0.9812999963760376,\n",
       " 0.9840999841690063,\n",
       " 0.9854999780654907,\n",
       " 0.9854000210762024,\n",
       " 0.9854000210762024]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_vals.append(accuracy_base)\n",
    "accuracy_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 565
    },
    "id": "L-ok0mKe3gaN",
    "outputId": "7266be13-6e2b-4bd4-9e8c-90bb8e0ec3d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 864x576 with 0 Axes>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f7e9a1ec550>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Dimension values')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Test Accuracy')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'SVD Networks Performance')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.legend:No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7e9a1e64d0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the test accuracies\n",
    "\n",
    "df_accuracy = pd.DataFrame(list(zip(['10', '20', '50', '100', '200', 'Full', 'Base'], accuracy_vals)), columns =['D_vals', 'Accuracy_vals'])\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(df_accuracy['D_vals'], df_accuracy['Accuracy_vals'])\n",
    "plt.xlabel('Dimension values')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('SVD Networks Performance')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lhJUc3wmsjPK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GC7QtJ2FketA"
   },
   "source": [
    "## Problem 2: Network Compression Using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mtP5VXi0dqLV",
    "outputId": "2d191564-5417-4f94-cff1-8cf5a7bab4a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the weights and bias of the model\n",
    "\n",
    "model_wts = []\n",
    "model_bias = []\n",
    "for i in range(len(model.layers)):\n",
    "  model_wts.append(model.layers[i].get_weights()[0])\n",
    "  model_bias.append(model.layers[i].get_weights()[1])\n",
    "\n",
    "len(model_wts), len(model_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "_V2fKoL_dve6"
   },
   "outputs": [],
   "source": [
    "# Performing svd on weights to get U, V\n",
    "\n",
    "V = [[] for i in range(5)]\n",
    "U = [[] for i in range(5)]\n",
    "\n",
    "for i in range(5):\n",
    "  s, u, v = tf.linalg.svd(model_wts[i], compute_uv=True)\n",
    "  V[i] = tf.matmul(tf.linalg.diag(s[:20]), v[:,:20], adjoint_b=True)\n",
    "  U[i] = u[:,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YbTVeFaAlz41",
    "outputId": "36d82b5c-3505-40e1-87bc-55f561c4ad7b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(U), len(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F3B4TSqUl2-b",
    "outputId": "470e837e-c418-4622-9497-eb8d0acaa836"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "1024\n",
      "1024\n",
      "1024\n",
      "1024\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  print(len(U[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOvRKxM_l7f2",
    "outputId": "b08990bf-633b-441f-bf7f-47526b7c457d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "20\n",
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "  print(len(V[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "73mb70b7mgWY"
   },
   "outputs": [],
   "source": [
    "# # Building a model \n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(1024, input_dim = 784,activation='relu'))\n",
    "# model.add(Dense(1024, input_dim = 1024,activation='relu'))\n",
    "# model.add(Dense(1024, input_dim = 1024,activation='relu'))\n",
    "# model.add(Dense(1024, input_dim = 1024,activation='relu'))\n",
    "# model.add(Dense(1024, input_dim = 1024,activation='relu'))\n",
    "# model.add(Dense(20, input_dim = 1024,activation='relu'))\n",
    "# model.add(Dense(20, input_dim = 20,activation='relu'))\n",
    "# model.add(Dense(20, input_dim = 20,activation='relu'))\n",
    "# model.add(Dense(20, input_dim = 20,activation='relu'))\n",
    "# model.add(Dense(20, input_dim = 20,activation='relu'))\n",
    "# model.add(Dense(10, input_dim = 20 ,activation='softmax'))\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uvupOcaRy6uG",
    "outputId": "9de4bd59-3f35-4657-81e9-ea03ac9b1645"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 20)                15700     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 20)                20500     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 20)                20500     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 20)                20500     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 20)                20500     \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1024)              21504     \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                10250     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 215,470\n",
      "Trainable params: 215,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Building a model \n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(20, input_dim = 784,activation=None))\n",
    "model.add(Dense(1024, input_dim = 20,activation='relu'))\n",
    "model.add(Dense(20, input_dim = 1024,activation=None))\n",
    "model.add(Dense(1024, input_dim = 20,activation='relu'))\n",
    "model.add(Dense(20, input_dim = 1024,activation=None))\n",
    "model.add(Dense(1024, input_dim = 20,activation='relu'))\n",
    "model.add(Dense(20, input_dim = 1024,activation=None))\n",
    "model.add(Dense(1024, input_dim = 20,activation='relu'))\n",
    "model.add(Dense(20, input_dim = 1024,activation=None))\n",
    "model.add(Dense(1024, input_dim = 20,activation='relu'))\n",
    "model.add(Dense(10, input_dim =1024 ,activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KL-anNXGnrIw"
   },
   "source": [
    "This architecture resulted in the least number of parameters compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "pTg1otyWJfSP"
   },
   "outputs": [],
   "source": [
    "# Calculating loss and optimizing it\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "9sUf0uQEuY6x"
   },
   "outputs": [],
   "source": [
    "# Initialising the weights using U and V from SVD\n",
    "\n",
    "u_ind = 0\n",
    "v_ind = 0\n",
    "for i in range(10):\n",
    "  if i in [0,2,4,6,8]:\n",
    "    model.layers[i].set_weights((U[u_ind], model_bias[u_ind][:20]))\n",
    "    u_ind+=1\n",
    "  else:\n",
    "    model.layers[i].set_weights((V[v_ind],model_bias[v_ind]))\n",
    "    v_ind+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bQcKzxw6dtMw",
    "outputId": "be45cfdc-233a-4870-eea0-2ddce114f5ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.1963 - accuracy: 0.9454\n",
      "Epoch 2/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0840 - accuracy: 0.9770\n",
      "Epoch 3/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0717 - accuracy: 0.9811\n",
      "Epoch 4/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0592 - accuracy: 0.9837\n",
      "Epoch 5/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0521 - accuracy: 0.9856\n",
      "Epoch 6/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0429 - accuracy: 0.9879\n",
      "Epoch 7/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0402 - accuracy: 0.9891\n",
      "Epoch 8/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0387 - accuracy: 0.9894\n",
      "Epoch 9/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0374 - accuracy: 0.9895\n",
      "Epoch 10/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0339 - accuracy: 0.9907\n",
      "Epoch 11/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0295 - accuracy: 0.9918\n",
      "Epoch 12/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0293 - accuracy: 0.9917\n",
      "Epoch 13/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0305 - accuracy: 0.9913\n",
      "Epoch 14/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0241 - accuracy: 0.9935\n",
      "Epoch 15/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0243 - accuracy: 0.9930\n",
      "Epoch 16/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0292 - accuracy: 0.9922\n",
      "Epoch 17/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0201 - accuracy: 0.9950\n",
      "Epoch 18/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0235 - accuracy: 0.9938\n",
      "Epoch 19/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0240 - accuracy: 0.9941\n",
      "Epoch 20/20\n",
      "600/600 [==============================] - 2s 3ms/step - loss: 0.0189 - accuracy: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e6b274d50>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "\n",
    "model.fit(x_train, y_train, epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wFKgZulvpKd6",
    "outputId": "bf7caedf-f5ae-402c-de4d-827a2634b1d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1258 - accuracy: 0.9774\n",
      "Test accuracy: 97.74\n"
     ]
    }
   ],
   "source": [
    "# Calculating test accuarcy \n",
    "\n",
    "loss, accuracy = model.evaluate(x_test,  y_test)\n",
    "print(\"Test accuracy:\", round(accuracy*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tA_mlnB51Uay"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4hKQLT42khL-"
   },
   "source": [
    "## Problem 3: Network Compression Using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSge3R6lQsEF",
    "outputId": "7afc4653-0033-47af-96b8-cfb6d15facb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 6)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the base model weights\n",
    "model.load_weights('model_weights.h5')\n",
    "\n",
    "# Getting the weights and bias of the base model\n",
    "model_wts = []\n",
    "model_bias = []\n",
    "for i in range(6):\n",
    "  model_wts.append(model.layers[i].get_weights()[0])\n",
    "  model_bias.append(model.layers[i].get_weights()[1])\n",
    "\n",
    "len(model_wts), len(model_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "NcI80xMms9sI"
   },
   "outputs": [],
   "source": [
    "# Function to define custome derivative\n",
    "\n",
    "@tf.custom_gradient\n",
    "def SetCustomWeights(wt):\n",
    "    s, u, v = tf.linalg.svd(wt, compute_uv=True, full_matrices=True)\n",
    "    sv = tf.matmul(tf.linalg.diag(s[:20]), v[:,:20], adjoint_b=True)\n",
    "    wts = tf.matmul(u[:,:20], sv)\n",
    "\n",
    "    def grad(dy):\n",
    "      gradient = tf.gradients(dy, wts)\n",
    "      return gradient\n",
    "\n",
    "    return wts, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "_rJ2kosTs9pm"
   },
   "outputs": [],
   "source": [
    "# Function to create custom layers\n",
    "\n",
    "class customLayers(keras.layers.Layer): \n",
    "\n",
    "     def __init__(self, units, layer_val, input_dim):\n",
    "      super(customLayers, self).__init__()\n",
    "      # w_init = tf.random_normal_initializer()\n",
    "      self.units = units\n",
    "      self.layer_val = layer_val\n",
    "      self.w=tf.Variable(\n",
    "            initial_value = model_wts[self.layer_val],\n",
    "            trainable=True,\n",
    "        )\n",
    "      # b_init = tf.zeros_initializer()\n",
    "      self.b=tf.Variable(\n",
    "            initial_value = model_bias[self.layer_val],\n",
    "            trainable=True,\n",
    "        )\n",
    "      \n",
    "      def call(self, inputs):\n",
    "          custom_wts1 = SetCustomWeights(self.w)  \n",
    "          custom_wts = keras.activations.relu(tf.matmul(inputs, custom_wts1)+self.b)\n",
    "          return custom_wts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HH76RSt2C1Zz"
   },
   "source": [
    "Reference - https://keras.io/guides/making_new_layers_and_models_via_subclassing/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "dA2RCAvMs9m6"
   },
   "outputs": [],
   "source": [
    "# Building a model and adding 4 hidden layers \n",
    "\n",
    "model = Sequential()\n",
    "model.add(customLayers(units=1024, layer_val=0, input_dim=(784,)))\n",
    "model.add(customLayers(units=1024, layer_val=1, input_dim=(1024,)))\n",
    "model.add(customLayers(units=1024, layer_val=2, input_dim=(1024,)))\n",
    "model.add(customLayers(units=1024, layer_val=3, input_dim=(1024,)))\n",
    "model.add(customLayers(units=1024, layer_val=4, input_dim=(1024,)))\n",
    "model.add(Dense(units=10,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "qTqNbNvys9jv"
   },
   "outputs": [],
   "source": [
    "# Calculating loss and optimizing it\n",
    "\n",
    "lr = 0.0001\n",
    "model.compile(tf.keras.optimizers.Adam(learning_rate=lr), loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MJgIfOVs9Lf",
    "outputId": "6e4076b4-b98f-4969-fe2b-39bd4f8c9df6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "60/60 [==============================] - 0s 5ms/step - loss: 0.2579 - accuracy: 0.9285 - val_loss: 0.2651 - val_accuracy: 0.9257\n",
      "Epoch 2/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2578 - accuracy: 0.9284 - val_loss: 0.2652 - val_accuracy: 0.9260\n",
      "Epoch 3/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2577 - accuracy: 0.9284 - val_loss: 0.2651 - val_accuracy: 0.9257\n",
      "Epoch 4/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2576 - accuracy: 0.9286 - val_loss: 0.2650 - val_accuracy: 0.9258\n",
      "Epoch 5/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.9285 - val_loss: 0.2650 - val_accuracy: 0.9257\n",
      "Epoch 6/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.9287 - val_loss: 0.2649 - val_accuracy: 0.9259\n",
      "Epoch 7/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2572 - accuracy: 0.9285 - val_loss: 0.2649 - val_accuracy: 0.9258\n",
      "Epoch 8/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.9287 - val_loss: 0.2649 - val_accuracy: 0.9258\n",
      "Epoch 9/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2570 - accuracy: 0.9287 - val_loss: 0.2648 - val_accuracy: 0.9260\n",
      "Epoch 10/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.9287 - val_loss: 0.2648 - val_accuracy: 0.9262\n",
      "Epoch 11/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2568 - accuracy: 0.9288 - val_loss: 0.2649 - val_accuracy: 0.9262\n",
      "Epoch 12/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2567 - accuracy: 0.9288 - val_loss: 0.2647 - val_accuracy: 0.9259\n",
      "Epoch 13/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2566 - accuracy: 0.9290 - val_loss: 0.2647 - val_accuracy: 0.9260\n",
      "Epoch 14/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2565 - accuracy: 0.9286 - val_loss: 0.2646 - val_accuracy: 0.9263\n",
      "Epoch 15/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2564 - accuracy: 0.9290 - val_loss: 0.2646 - val_accuracy: 0.9262\n",
      "Epoch 16/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2563 - accuracy: 0.9291 - val_loss: 0.2645 - val_accuracy: 0.9262\n",
      "Epoch 17/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.9288 - val_loss: 0.2645 - val_accuracy: 0.9262\n",
      "Epoch 18/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2561 - accuracy: 0.9291 - val_loss: 0.2644 - val_accuracy: 0.9264\n",
      "Epoch 19/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2560 - accuracy: 0.9291 - val_loss: 0.2644 - val_accuracy: 0.9262\n",
      "Epoch 20/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2559 - accuracy: 0.9291 - val_loss: 0.2644 - val_accuracy: 0.9264\n",
      "Epoch 21/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2558 - accuracy: 0.9292 - val_loss: 0.2643 - val_accuracy: 0.9264\n",
      "Epoch 22/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2557 - accuracy: 0.9290 - val_loss: 0.2642 - val_accuracy: 0.9264\n",
      "Epoch 23/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2556 - accuracy: 0.9291 - val_loss: 0.2642 - val_accuracy: 0.9263\n",
      "Epoch 24/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2555 - accuracy: 0.9290 - val_loss: 0.2644 - val_accuracy: 0.9265\n",
      "Epoch 25/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2554 - accuracy: 0.9293 - val_loss: 0.2642 - val_accuracy: 0.9266\n",
      "Epoch 26/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2553 - accuracy: 0.9291 - val_loss: 0.2641 - val_accuracy: 0.9266\n",
      "Epoch 27/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2552 - accuracy: 0.9292 - val_loss: 0.2640 - val_accuracy: 0.9265\n",
      "Epoch 28/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2551 - accuracy: 0.9291 - val_loss: 0.2641 - val_accuracy: 0.9265\n",
      "Epoch 29/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2550 - accuracy: 0.9293 - val_loss: 0.2640 - val_accuracy: 0.9267\n",
      "Epoch 30/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2549 - accuracy: 0.9291 - val_loss: 0.2639 - val_accuracy: 0.9266\n",
      "Epoch 31/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2548 - accuracy: 0.9294 - val_loss: 0.2640 - val_accuracy: 0.9265\n",
      "Epoch 32/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.9293 - val_loss: 0.2639 - val_accuracy: 0.9267\n",
      "Epoch 33/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2547 - accuracy: 0.9293 - val_loss: 0.2638 - val_accuracy: 0.9266\n",
      "Epoch 34/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2545 - accuracy: 0.9294 - val_loss: 0.2639 - val_accuracy: 0.9266\n",
      "Epoch 35/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2544 - accuracy: 0.9294 - val_loss: 0.2638 - val_accuracy: 0.9266\n",
      "Epoch 36/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.9293 - val_loss: 0.2638 - val_accuracy: 0.9267\n",
      "Epoch 37/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.9295 - val_loss: 0.2637 - val_accuracy: 0.9266\n",
      "Epoch 38/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2542 - accuracy: 0.9294 - val_loss: 0.2637 - val_accuracy: 0.9265\n",
      "Epoch 39/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2541 - accuracy: 0.9295 - val_loss: 0.2636 - val_accuracy: 0.9261\n",
      "Epoch 40/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2540 - accuracy: 0.9295 - val_loss: 0.2637 - val_accuracy: 0.9266\n",
      "Epoch 41/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2539 - accuracy: 0.9294 - val_loss: 0.2636 - val_accuracy: 0.9267\n",
      "Epoch 42/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2538 - accuracy: 0.9296 - val_loss: 0.2636 - val_accuracy: 0.9265\n",
      "Epoch 43/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2537 - accuracy: 0.9296 - val_loss: 0.2636 - val_accuracy: 0.9267\n",
      "Epoch 44/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2537 - accuracy: 0.9295 - val_loss: 0.2635 - val_accuracy: 0.9268\n",
      "Epoch 45/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.9298 - val_loss: 0.2635 - val_accuracy: 0.9263\n",
      "Epoch 46/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2535 - accuracy: 0.9297 - val_loss: 0.2634 - val_accuracy: 0.9267\n",
      "Epoch 47/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2534 - accuracy: 0.9297 - val_loss: 0.2634 - val_accuracy: 0.9269\n",
      "Epoch 48/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2533 - accuracy: 0.9297 - val_loss: 0.2633 - val_accuracy: 0.9267\n",
      "Epoch 49/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2532 - accuracy: 0.9298 - val_loss: 0.2635 - val_accuracy: 0.9263\n",
      "Epoch 50/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2531 - accuracy: 0.9298 - val_loss: 0.2633 - val_accuracy: 0.9264\n",
      "Epoch 51/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.9300 - val_loss: 0.2633 - val_accuracy: 0.9266\n",
      "Epoch 52/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2530 - accuracy: 0.9296 - val_loss: 0.2632 - val_accuracy: 0.9263\n",
      "Epoch 53/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2529 - accuracy: 0.9299 - val_loss: 0.2632 - val_accuracy: 0.9265\n",
      "Epoch 54/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.9299 - val_loss: 0.2631 - val_accuracy: 0.9268\n",
      "Epoch 55/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2527 - accuracy: 0.9302 - val_loss: 0.2632 - val_accuracy: 0.9266\n",
      "Epoch 56/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2526 - accuracy: 0.9298 - val_loss: 0.2631 - val_accuracy: 0.9266\n",
      "Epoch 57/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2526 - accuracy: 0.9299 - val_loss: 0.2632 - val_accuracy: 0.9267\n",
      "Epoch 58/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2525 - accuracy: 0.9302 - val_loss: 0.2631 - val_accuracy: 0.9268\n",
      "Epoch 59/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2524 - accuracy: 0.9300 - val_loss: 0.2630 - val_accuracy: 0.9265\n",
      "Epoch 60/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2523 - accuracy: 0.9301 - val_loss: 0.2631 - val_accuracy: 0.9265\n",
      "Epoch 61/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2522 - accuracy: 0.9301 - val_loss: 0.2630 - val_accuracy: 0.9268\n",
      "Epoch 62/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2522 - accuracy: 0.9303 - val_loss: 0.2630 - val_accuracy: 0.9264\n",
      "Epoch 63/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2521 - accuracy: 0.9302 - val_loss: 0.2630 - val_accuracy: 0.9268\n",
      "Epoch 64/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2520 - accuracy: 0.9303 - val_loss: 0.2628 - val_accuracy: 0.9269\n",
      "Epoch 65/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2519 - accuracy: 0.9303 - val_loss: 0.2628 - val_accuracy: 0.9268\n",
      "Epoch 66/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2518 - accuracy: 0.9302 - val_loss: 0.2629 - val_accuracy: 0.9266\n",
      "Epoch 67/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2518 - accuracy: 0.9304 - val_loss: 0.2628 - val_accuracy: 0.9270\n",
      "Epoch 68/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2517 - accuracy: 0.9303 - val_loss: 0.2627 - val_accuracy: 0.9271\n",
      "Epoch 69/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9302 - val_loss: 0.2627 - val_accuracy: 0.9271\n",
      "Epoch 70/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.9302 - val_loss: 0.2627 - val_accuracy: 0.9269\n",
      "Epoch 71/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.9303 - val_loss: 0.2628 - val_accuracy: 0.9268\n",
      "Epoch 72/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.9303 - val_loss: 0.2627 - val_accuracy: 0.9272\n",
      "Epoch 73/100\n",
      "60/60 [==============================] - 0s 3ms/step - loss: 0.2513 - accuracy: 0.9306 - val_loss: 0.2626 - val_accuracy: 0.9266\n",
      "Epoch 74/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2512 - accuracy: 0.9304 - val_loss: 0.2627 - val_accuracy: 0.9268\n",
      "Epoch 75/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2512 - accuracy: 0.9303 - val_loss: 0.2627 - val_accuracy: 0.9269\n",
      "Epoch 76/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2511 - accuracy: 0.9305 - val_loss: 0.2626 - val_accuracy: 0.9270\n",
      "Epoch 77/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2510 - accuracy: 0.9305 - val_loss: 0.2627 - val_accuracy: 0.9271\n",
      "Epoch 78/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.9306 - val_loss: 0.2626 - val_accuracy: 0.9266\n",
      "Epoch 79/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2509 - accuracy: 0.9306 - val_loss: 0.2626 - val_accuracy: 0.9269\n",
      "Epoch 80/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2508 - accuracy: 0.9308 - val_loss: 0.2625 - val_accuracy: 0.9271\n",
      "Epoch 81/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.9307 - val_loss: 0.2627 - val_accuracy: 0.9268\n",
      "Epoch 82/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.9305 - val_loss: 0.2625 - val_accuracy: 0.9268\n",
      "Epoch 83/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2506 - accuracy: 0.9308 - val_loss: 0.2625 - val_accuracy: 0.9270\n",
      "Epoch 84/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.9308 - val_loss: 0.2623 - val_accuracy: 0.9271\n",
      "Epoch 85/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.9307 - val_loss: 0.2624 - val_accuracy: 0.9271\n",
      "Epoch 86/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2504 - accuracy: 0.9306 - val_loss: 0.2624 - val_accuracy: 0.9269\n",
      "Epoch 87/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.9307 - val_loss: 0.2624 - val_accuracy: 0.9272\n",
      "Epoch 88/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2503 - accuracy: 0.9308 - val_loss: 0.2625 - val_accuracy: 0.9268\n",
      "Epoch 89/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2502 - accuracy: 0.9307 - val_loss: 0.2624 - val_accuracy: 0.9268\n",
      "Epoch 90/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.9307 - val_loss: 0.2623 - val_accuracy: 0.9268\n",
      "Epoch 91/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2500 - accuracy: 0.9307 - val_loss: 0.2622 - val_accuracy: 0.9272\n",
      "Epoch 92/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2500 - accuracy: 0.9309 - val_loss: 0.2622 - val_accuracy: 0.9274\n",
      "Epoch 93/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2499 - accuracy: 0.9311 - val_loss: 0.2623 - val_accuracy: 0.9271\n",
      "Epoch 94/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2498 - accuracy: 0.9309 - val_loss: 0.2622 - val_accuracy: 0.9268\n",
      "Epoch 95/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.9308 - val_loss: 0.2622 - val_accuracy: 0.9272\n",
      "Epoch 96/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2497 - accuracy: 0.9310 - val_loss: 0.2622 - val_accuracy: 0.9270\n",
      "Epoch 97/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.9310 - val_loss: 0.2622 - val_accuracy: 0.9268\n",
      "Epoch 98/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2496 - accuracy: 0.9310 - val_loss: 0.2621 - val_accuracy: 0.9268\n",
      "Epoch 99/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2495 - accuracy: 0.9311 - val_loss: 0.2622 - val_accuracy: 0.9269\n",
      "Epoch 100/100\n",
      "60/60 [==============================] - 0s 4ms/step - loss: 0.2494 - accuracy: 0.9310 - val_loss: 0.2620 - val_accuracy: 0.9272\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "\n",
    "model_hist=model.fit(x=x_train, y=y_train, epochs=100, batch_size=1000, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1nf90OkmtNht",
    "outputId": "cd5d3c8b-eeb2-4108-b8ea-7a91e6c027d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2620 - accuracy: 0.9272\n",
      "Test accuracy: 92.72\n"
     ]
    }
   ],
   "source": [
    "# Calculating test accuarcy \n",
    "\n",
    "loss, accuracy = model.evaluate(x_test, y_test)\n",
    "print(\"Test accuracy:\", round(accuracy*100,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9ttOAZacyu-U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zuRdFcUhkib_"
   },
   "source": [
    "## Problem 4: Speaker Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "kVdygQ8Lkmu-"
   },
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "\n",
    "with open('hw4_trs.pkl','rb') as file:\n",
    "  trs=pickle.load(file)\n",
    "\n",
    "with open('hw4_tes.pkl','rb') as file:\n",
    "  tes=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dHxyqFwEV40E",
    "outputId": "c54cc897-88ae-4c27-9070-d925e7a18ef1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 16180), (200, 22631))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trs.shape, tes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fO2CmkbWG_D",
    "outputId": "2194205e-cd09-442f-cc85-0f9f8d3f245c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 513, 32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coverting train signals into spectograms\n",
    "\n",
    "trs_stft = []\n",
    "\n",
    "for i in range(len(trs)):\n",
    "  trs_S = librosa.stft(trs[i], n_fft=1024, hop_length=512)\n",
    "  trs_abs = np.abs(trs_S)\n",
    "  trs_stft.append(trs_abs)\n",
    "\n",
    "trs_stft = np.array(trs_stft)\n",
    "trs_stft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "btP0cZV0XOJe",
    "outputId": "3cc6a829-93b8-4429-b1c6-30c1014b7b55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 513, 45)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Coverting test signals into spectograms\n",
    "\n",
    "tes_stft = []\n",
    "\n",
    "for i in range(len(tes)):\n",
    "  tes_S = librosa.stft(tes[i], n_fft=1024, hop_length=512)\n",
    "  tes_abs = np.abs(tes_S)\n",
    "  tes_stft.append(tes_abs)\n",
    "\n",
    "tes_stft = np.array(tes_stft)\n",
    "tes_stft.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "6mntSso9ribp"
   },
   "outputs": [],
   "source": [
    "# Function to sample positive pairs\n",
    "\n",
    "def posSampling(spk_index, df):\n",
    "  pos_data = []\n",
    "  for i in spk_index:\n",
    "    spk_list = [i for i in range(i,i+10)]\n",
    "    pair1_index = np.random.choice(spk_list,size=45,replace=True)\n",
    "    pair1_data = df[pair1_index]\n",
    "    \n",
    "    pair2_index = np.random.choice(spk_list,size=45,replace=True)\n",
    "    pair2_data = df[pair2_index]\n",
    "    \n",
    "    if i==0:\n",
    "      pos_data =  np.concatenate((pair1_data, pair2_data))\n",
    "    else:\n",
    "      pos_data = np.concatenate((pos_data, pair1_data, pair2_data))\n",
    "\n",
    "  return pos_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3BqI5buJskbn",
    "outputId": "0ceee61c-b261-4a22-8dca-7c83d5323bcf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 513, 32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1800, 513, 45)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling postive pairs for train and test data\n",
    "\n",
    "trs_speakers_index = []\n",
    "for i in range(0,len(trs_stft),10):\n",
    "  trs_speakers_index.append(i)\n",
    "trs_pos_data = posSampling(trs_speakers_index, trs_stft)\n",
    "trs_pos_data.shape\n",
    "\n",
    "tes_speakers_index = []\n",
    "for i in range(0,len(tes_stft),10):\n",
    "  tes_speakers_index.append(i)\n",
    "tes_pos_data = posSampling(tes_speakers_index, tes_stft)\n",
    "tes_pos_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "7R_mVLoqs61T"
   },
   "outputs": [],
   "source": [
    "# Function to sample negtaive pairs\n",
    "\n",
    "def negSampling(spk_index,total_list,df):\n",
    "  neg_data = []\n",
    "  for i in spk_index:\n",
    "    spk_list = [i for i in range(i,i+10)]\n",
    "    rem_spk_list = ([x for x in total_list if x not in set(spk_list)])\n",
    "\n",
    "    pair1_index = np.random.choice(rem_spk_list,size=45,replace=False)\n",
    "    pair1_data = df[pair1_index]\n",
    "  \n",
    "    pair2_index = np.random.choice(spk_list,size=45,replace=True)\n",
    "    pair2_data = df[pair2_index]\n",
    "  \n",
    "    if i==0:\n",
    "      neg_data =  np.concatenate((pair1_data, pair2_data))\n",
    "    else:\n",
    "      neg_data = np.concatenate((neg_data, pair1_data, pair2_data))\n",
    "  \n",
    "  return neg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuHVoGpBwVkO",
    "outputId": "091ada28-27ed-4cf4-d17b-4af32c8e7dfd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 513, 32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1800, 513, 45)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sampling negative pairs for train and test data\n",
    "\n",
    "trs_total_list = [i for i in range(0,len(trs_stft))]\n",
    "trs_neg_data = negSampling(trs_speakers_index,trs_total_list,trs_stft)\n",
    "trs_neg_data.shape\n",
    "\n",
    "tes_total_list = [i for i in range(0,len(tes_stft))]\n",
    "tes_neg_data = negSampling(tes_speakers_index,tes_total_list,tes_stft)\n",
    "tes_neg_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPQkXMzzxptt",
    "outputId": "c3ee23d0-9de4-46d6-e128-599c5dc78d84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4500, 1800)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating labels for train and test data\n",
    "\n",
    "trs_labels = []\n",
    "for i in range(0,50):\n",
    "  ones = np.ones((45,1))\n",
    "  zeros = np.zeros((45,1))\n",
    "  if i==0:\n",
    "    trs_labels =  np.concatenate((ones, zeros))\n",
    "  else:\n",
    "    trs_labels = np.concatenate((trs_labels, ones, zeros))\n",
    "\n",
    "tes_labels = []\n",
    "for i in range(0,20):\n",
    "  ones = np.ones((45,1))\n",
    "  zeros = np.zeros((45,1))\n",
    "  if i==0:\n",
    "    tes_labels =  np.concatenate((ones, zeros))\n",
    "  else:\n",
    "    tes_labels = np.concatenate((tes_labels, ones, zeros))\n",
    "\n",
    "len(trs_labels),len(tes_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "UV2LGhnqzT-8"
   },
   "outputs": [],
   "source": [
    "# Function to build a Siamese model\n",
    "\n",
    "def siameseModel(inputShape, embeddingDim=48):\n",
    "  inputs = Input(inputShape) # Define input\n",
    "  x = GRU(activation='tanh', units=64, return_sequences=False)(inputs) # Define layers\n",
    "  outputs = Dense(embeddingDim)(x)   # Define output\n",
    "  model = Model(inputs, outputs)  # Build the model\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "FTMbCcjp7eTr"
   },
   "outputs": [],
   "source": [
    "# Configuring the siamese network\n",
    "\n",
    "pos_input = Input(shape=(None,513))\n",
    "neg_input = Input(shape=(None,513))\n",
    "featureExtractor = siameseModel((None,513))\n",
    "embed_vec1 = featureExtractor(pos_input)\n",
    "embed_vec2 = featureExtractor(neg_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "z6BRRE7V7eXD"
   },
   "outputs": [],
   "source": [
    "# Fucntion to calculate the inner product of the two latent embedding vectors\n",
    "\n",
    "def distanceCalc(input1, input2):\n",
    "  dist = tf.multiply(input1, input2)\n",
    "  return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "VVaOio7J7ear"
   },
   "outputs": [],
   "source": [
    "# Constructing the siamese network\n",
    "\n",
    "distance = distanceCalc(embed_vec1, embed_vec2)\n",
    "outputs = Dense(1, activation=\"sigmoid\")(distance)\n",
    "model = Model(inputs=[pos_input, neg_input], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "On5EymaH-B9J"
   },
   "outputs": [],
   "source": [
    "# Calculating loss and optimizing the model\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RrB9AiUD9uGN",
    "outputId": "b23006fe-5740-42d4-a824-548056d16281"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4500, 32, 513), (4500, 32, 513))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((1800, 45, 513), (1800, 45, 513))"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Changing the shape of train and test data\n",
    "\n",
    "trs_pos_data1 = np.transpose(trs_pos_data,axes=(0,2,1))\n",
    "trs_neg_data1 = np.transpose(trs_neg_data,axes=(0,2,1))\n",
    "trs_pos_data1.shape, trs_neg_data1.shape\n",
    "\n",
    "tes_pos_data1 = np.transpose(tes_pos_data,axes=(0,2,1))\n",
    "tes_neg_data1 = np.transpose(tes_neg_data,axes=(0,2,1))\n",
    "tes_pos_data1.shape, tes_neg_data1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LtdFLkNB93SZ",
    "outputId": "0a8ea06f-0d4d-4d55-fdd2-f2b81f58707e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "45/45 [==============================] - 1s 26ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.3201 - val_accuracy: 0.6617\n",
      "Epoch 2/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.3008 - val_accuracy: 0.6661\n",
      "Epoch 3/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.3568 - val_accuracy: 0.6617\n",
      "Epoch 4/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 9.9403e-04 - accuracy: 1.0000 - val_loss: 2.3697 - val_accuracy: 0.6650\n",
      "Epoch 5/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 9.0419e-04 - accuracy: 1.0000 - val_loss: 2.3658 - val_accuracy: 0.6650\n",
      "Epoch 6/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 8.4350e-04 - accuracy: 1.0000 - val_loss: 2.4096 - val_accuracy: 0.6667\n",
      "Epoch 7/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 7.8773e-04 - accuracy: 1.0000 - val_loss: 2.4777 - val_accuracy: 0.6589\n",
      "Epoch 8/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 7.3755e-04 - accuracy: 1.0000 - val_loss: 2.4176 - val_accuracy: 0.6644\n",
      "Epoch 9/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 6.8700e-04 - accuracy: 1.0000 - val_loss: 2.5051 - val_accuracy: 0.6656\n",
      "Epoch 10/10\n",
      "45/45 [==============================] - 1s 15ms/step - loss: 6.3770e-04 - accuracy: 1.0000 - val_loss: 2.5262 - val_accuracy: 0.6633\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7e6d5c6190>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the model\n",
    "\n",
    "model.fit([trs_pos_data1, trs_neg_data1], trs_labels,\n",
    "          validation_data=([tes_pos_data1, tes_neg_data1], tes_labels),\n",
    "\t        batch_size=100, \n",
    "\t        epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmP-T0kT-3KL",
    "outputId": "66c6f3b6-3ead-45d2-d9a4-6b7b77b8c075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 0s 5ms/step\n",
      "Test accuracy: 66.22\n"
     ]
    }
   ],
   "source": [
    "# Calculating test accuarcy \n",
    "\n",
    "preds = model.predict([tes_pos_data1,tes_neg_data1])\n",
    "preds1 = preds>=0.5\n",
    "accuracy = (sum(preds1 == tes_labels)/len(tes_labels))[0]\n",
    "print(\"Test accuracy:\", round(accuracy*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O_onsLTlBtVK"
   },
   "source": [
    "Reference - https://pyimagesearch.com/2020/11/30/siamese-networks-with-keras-tensorflow-and-deep-learning/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e8SYXgGZ9uJD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
